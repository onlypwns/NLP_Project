{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"file_name.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word tokenize each column of interest from the df\n",
    "import nltk\n",
    "from nltk import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data['Date Created'] = pd.to_datetime(data['Date Created'],unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Title', 'Political Lean', 'Score', 'Id', 'Subreddit', 'URL',\n",
       "       'Num of Comments', 'Text', 'Date Created'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Political Lean\n",
       "Conservative    4535\n",
       "Liberal         8319\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['Political Lean']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subreddit\n",
       "Capitalism              975\n",
       "Communist               574\n",
       "DemocraticSocialism     922\n",
       "Liberal                 904\n",
       "Libertarian             975\n",
       "RadicalFeminism         100\n",
       "SocialDemocracy         997\n",
       "alltheleft              997\n",
       "anarchocapitalism       637\n",
       "conservatives          1000\n",
       "democrats               941\n",
       "feminisms               935\n",
       "progressive             974\n",
       "republicans             948\n",
       "socialism               975\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(['Subreddit']).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subreddit\n",
       "Communist              574\n",
       "DemocraticSocialism    922\n",
       "Liberal                904\n",
       "RadicalFeminism        100\n",
       "SocialDemocracy        997\n",
       "alltheleft             997\n",
       "democrats              941\n",
       "feminisms              935\n",
       "progressive            974\n",
       "socialism              975\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "liberal_df = data[data['Political Lean'] == 'Liberal']\n",
    "liberal_df.groupby('Subreddit').size()\n",
    "#print(len(liberal_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Subreddit\n",
       "Capitalism            975\n",
       "Libertarian           975\n",
       "anarchocapitalism     637\n",
       "conservatives        1000\n",
       "republicans           948\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conservative_df = data[data['Political Lean'] == 'Conservative']\n",
    "conservative_df.groupby('Subreddit').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       Who watched the state of the union last night ...\n",
       "11      I have fallen for this trap several times and ...\n",
       "20      One of the things I have noticed in todays wor...\n",
       "42      [https://kites-journal.org/2022/03/01/between-...\n",
       "54      ***\"Axe tax\"*** aka ***\"Hammer tax\"*** aka ***...\n",
       "                              ...                        \n",
       "8159    http://www.facebook.com/event.php?eid=27851760...\n",
       "8187                                     just wonderin :p\n",
       "8213    Ok to start off I'm not communist, I'm liberta...\n",
       "8250    Please forward\\n\\n \\n\\nCCR EXPLAINS HLP v. HOL...\n",
       "8280    I think a little materialist analysis on the c...\n",
       "Name: Text, Length: 1471, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenize liberal text\n",
    "\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "liberal_data = data[data['Political Lean'] == 'Liberal']\n",
    "test = liberal_data['Text']\n",
    "test = test.dropna()\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_lib = \" \"\n",
    "for text in test:     # convert from column texts to string\n",
    "    t_lib+=str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_lib = t_lib.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "t_lib = re.sub(r'\\d+', '', t_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "t_lib = t_lib.translate(str.maketrans(\"\",\"\", string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = word_tokenize(t_lib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "# add more words to stopwords\n",
    "my_words=['th','would', 'https', '’', '”', '“', '’']\n",
    "stop_words.extend(my_words)\n",
    "tok = word_tokenize(t_lib)\n",
    "result = [i for i in tok if not i in stop_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 1154),\n",
       " ('like', 965),\n",
       " ('one', 706),\n",
       " ('us', 664),\n",
       " ('social', 624),\n",
       " ('party', 594),\n",
       " ('workers', 566),\n",
       " ('also', 555),\n",
       " ('think', 507),\n",
       " ('even', 484)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(result)\n",
    "fdist = fdist.most_common(10)\n",
    "fdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'would': 1060, 'their': 1047, 'about': 1005, 'which': 741, 'there': 680, 'other': 600, 'party': 594, 'these': 516, 'think': 507, 'being': 434, ...})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import ConditionalFreqDist\n",
    "cfdist = ConditionalFreqDist()\n",
    "\n",
    "for word in word_tokenize(t_lib): \n",
    "    condition = len(word)\n",
    "    cfdist[condition][word] += 1\n",
    "cfdist[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0890375085745266\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "tb = TextBlob(t_lib)\n",
    "print(tb.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'us': 664, 'im': 372, 'go': 195, 'xb': 184, 'id': 95, 'eu': 62, 'uk': 50, '•b': 41, 'ie': 40, 'na': 38, ...})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "cfdist = ConditionalFreqDist()\n",
    "\n",
    "for word in result: \n",
    "    condition = len(word)\n",
    "    cfdist[condition][word] += 1\n",
    "cfdist[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('working', 'class'), 161),\n",
       " (('social', 'democracy'), 132),\n",
       " (('social', 'democratic'), 86),\n",
       " (('united', 'states'), 86),\n",
       " (('social', 'democrats'), 70),\n",
       " (('soviet', 'union'), 62),\n",
       " (('democratic', 'party'), 50),\n",
       " (('means', 'production'), 48),\n",
       " (('feel', 'like'), 48),\n",
       " (('many', 'people'), 47)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgs = nltk.bigrams(result)\n",
    "fdist_bgs = nltk.FreqDist(bgs)\n",
    "fdist_bgs.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parts of speech\n",
    "tagged = nltk.pos_tag(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('people', 'NNS'), 1154),\n",
       " (('like', 'IN'), 949),\n",
       " (('one', 'CD'), 706),\n",
       " (('us', 'PRP'), 664),\n",
       " (('social', 'JJ'), 624),\n",
       " (('party', 'NN'), 594),\n",
       " (('workers', 'NNS'), 566),\n",
       " (('also', 'RB'), 555),\n",
       " (('even', 'RB'), 483),\n",
       " (('government', 'NN'), 451),\n",
       " (('time', 'NN'), 448),\n",
       " (('think', 'VBP'), 423),\n",
       " (('state', 'NN'), 419),\n",
       " (('many', 'JJ'), 415),\n",
       " (('new', 'JJ'), 397)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# distribution of parts of speech\n",
    "fdis = FreqDist(tagged)\n",
    "fdis = fdis.most_common(15)\n",
    "fdis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('tries', 'leave', 'russiancolonialism'), 25),\n",
       " (('free', 'discuss', 'whatever'), 20),\n",
       " (('discuss', 'whatever', 'please'), 20),\n",
       " (('whatever', 'please', 'socdem'), 20),\n",
       " (('please', 'socdem', 'related'), 20),\n",
       " (('socdem', 'related', 'entirely'), 20),\n",
       " (('related', 'entirely', 'unrelated'), 20),\n",
       " (('entirely', 'unrelated', 'whatever'), 20),\n",
       " (('unrelated', 'whatever', 'youd'), 20),\n",
       " (('leave', 'russiancolonialism', 'moscow'), 15),\n",
       " (('social', 'democratic', 'party'), 15),\n",
       " (('world', 'war', 'ii'), 15),\n",
       " (('social', 'democratic', 'parties'), 11),\n",
       " (('ownership', 'means', 'production'), 11),\n",
       " (('new', 'york', 'times'), 10)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trig = nltk.trigrams(result)\n",
    "fdistr = nltk.FreqDist(trig)\n",
    "fdistr.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 52832),\n",
       " ('JJ', 32962),\n",
       " ('NNS', 21159),\n",
       " ('RB', 10640),\n",
       " ('VBP', 9780),\n",
       " ('VBG', 7139),\n",
       " ('VBD', 6844),\n",
       " ('VBN', 3879),\n",
       " ('IN', 3171),\n",
       " ('VBZ', 3025),\n",
       " ('VB', 3021),\n",
       " ('CD', 1210),\n",
       " ('MD', 909),\n",
       " ('JJR', 695),\n",
       " ('PRP', 683),\n",
       " ('NNP', 509),\n",
       " ('JJS', 451),\n",
       " ('DT', 435),\n",
       " ('RBR', 400),\n",
       " ('FW', 218)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_fd = nltk.FreqDist(tag for (word, tag) in tagged)\n",
    "tag_fd.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# liberals mentioning specific words\n",
    "\n",
    "fdist_w = FreqDist(tok)\n",
    "vocab = fdist_w.keys()\n",
    "fdist_w['biden']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END OF LIB PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test3 = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8328     Socialism  is a redistribution system not a we...\n",
       "8344     1) After informing Derek about his sore stomac...\n",
       "8345     What are folks thinking.\\n\\nI was *impressed* ...\n",
       "8357                                               Curious\n",
       "8359                             Holy shit. We’re screwed.\n",
       "                               ...                        \n",
       "12829    \"Well now, which is the longest river in Afric...\n",
       "12837    Let's say there are private courts/resolution ...\n",
       "12838    Basically, the above. It can be a very effecti...\n",
       "12842    Last week I would've considered myself a liber...\n",
       "12853    I go to the mises.org and listen to the writin...\n",
       "Name: Text, Length: 957, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word tokenize conservative text\n",
    "conservative_data = data[data['Political Lean'] == 'Conservative']\n",
    "test = conservative_data['Text']\n",
    "test3 = test.dropna()\n",
    "test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# method n2 to remove punctuation\n",
    "#tok2 = tok\n",
    "#tok = list(filter(lambda tok: tok not in string.punctuation, tok))\n",
    "#tok2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_conserv = \" \"\n",
    "for text in test3:     # convert from column texts to string\n",
    "    t_conserv+=str(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_conserv = t_conserv.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "t_conserv = re.sub(r'\\d+', '', t_conserv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "t_conserv = t_conserv.translate(str.maketrans(\"\",\"\", string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tokc = word_tokenize(t_conserv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "s_words = stopwords.words('english')\n",
    "\n",
    "my_words=['th','would', 'https', '’', '”', '“', \"’\", '’']\n",
    "s_words.extend(my_words)\n",
    "\n",
    "tokc = word_tokenize(t_conserv)\n",
    "result1 = [c for c in tokc if not c in s_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('people', 708),\n",
       " ('like', 415),\n",
       " ('government', 359),\n",
       " ('one', 320),\n",
       " ('us', 290),\n",
       " ('think', 278),\n",
       " ('get', 270),\n",
       " ('dont', 244),\n",
       " ('even', 241),\n",
       " ('capitalism', 236)]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist1 = FreqDist(result1)\n",
    "fdist1 = fdist1.most_common(10)\n",
    "fdist1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('free', 'market'), 56),\n",
       " (('minimum', 'wage'), 47),\n",
       " (('united', 'states'), 31),\n",
       " (('things', 'like'), 27),\n",
       " (('many', 'people'), 27),\n",
       " (('dont', 'know'), 24),\n",
       " (('seems', 'like'), 21),\n",
       " (('private', 'property'), 21),\n",
       " (('dont', 'want'), 20),\n",
       " (('middle', 'class'), 18)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bgs1 = nltk.bigrams(result1)\n",
    "fdist_bgs1 = nltk.FreqDist(bgs1)\n",
    "fdist_bgs1.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# conservatives mentioning capitalism \n",
    "\n",
    "fdist = FreqDist(tokc)\n",
    "vocab = fdist.keys()\n",
    "fdist['biden']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08423891682332069\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "tb = TextBlob(t_conserv)\n",
    "print(tb.sentiment.polarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looks like you processed it well\n",
    "if I was trying to get more context of what they are saying\n",
    "I'd look at bigrams and trygram fredist\n",
    "FreqDist\n",
    "(trigram) can't type today\n",
    "you could take what you have an also make a text classifier with a few modifications\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tagged parts of speech\n",
    "taggedc = nltk.pos_tag(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('people', 'NNS'), 708),\n",
       " (('like', 'IN'), 410),\n",
       " (('government', 'NN'), 359),\n",
       " (('one', 'CD'), 318),\n",
       " (('us', 'PRP'), 290),\n",
       " (('even', 'RB'), 240),\n",
       " (('capitalism', 'NN'), 227),\n",
       " (('money', 'NN'), 224),\n",
       " (('think', 'VBP'), 221),\n",
       " (('could', 'MD'), 215),\n",
       " (('also', 'RB'), 207),\n",
       " (('state', 'NN'), 203)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdisc = FreqDist(taggedc)\n",
    "fdisc = fdisc.most_common(12)\n",
    "fdisc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('free', 'market'), 56),\n",
       " (('minimum', 'wage'), 47),\n",
       " (('united', 'states'), 31),\n",
       " (('things', 'like'), 27),\n",
       " (('many', 'people'), 27),\n",
       " (('dont', 'know'), 24),\n",
       " (('seems', 'like'), 21),\n",
       " (('private', 'property'), 21),\n",
       " (('dont', 'want'), 20),\n",
       " (('middle', 'class'), 18),\n",
       " (('get', 'rid'), 17),\n",
       " (('people', 'dont'), 17),\n",
       " (('goods', 'services'), 17),\n",
       " (('dont', 'think'), 16),\n",
       " (('lets', 'say'), 16)]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bigram\n",
    "\n",
    "bgsc = nltk.bigrams(result1)\n",
    "fdist_bgsc = nltk.FreqDist(bgsc)\n",
    "fdist_bgsc.most_common(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('it', '’', 's'), 93),\n",
       " (('a', 'lot', 'of'), 70),\n",
       " (('i', '’', 'm'), 63),\n",
       " (('don', '’', 't'), 58),\n",
       " (('be', 'able', 'to'), 36),\n",
       " (('one', 'of', 'the'), 31),\n",
       " (('to', 'be', 'a'), 29),\n",
       " (('in', 'order', 'to'), 29),\n",
       " (('the', 'united', 'states'), 27),\n",
       " (('there', 'is', 'no'), 26)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# trigram\n",
    "\n",
    "trigc = nltk.trigrams(tokc)\n",
    "fdist_trigc = nltk.FreqDist(trigc)\n",
    "fdist_trigc.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 23615),\n",
       " ('JJ', 13781),\n",
       " ('NNS', 9004),\n",
       " ('VBP', 4629),\n",
       " ('RB', 4585),\n",
       " ('VBG', 3142),\n",
       " ('VBD', 2643),\n",
       " ('VBN', 1618),\n",
       " ('VB', 1528),\n",
       " ('VBZ', 1497),\n",
       " ('IN', 1380),\n",
       " ('CD', 603),\n",
       " ('MD', 461),\n",
       " ('JJR', 335),\n",
       " ('PRP', 301),\n",
       " ('DT', 252),\n",
       " ('JJS', 246),\n",
       " ('NNP', 235),\n",
       " ('RBR', 194),\n",
       " ('FW', 105)]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_fd1 = nltk.FreqDist(tag for (word, tag) in taggedc)\n",
    "tag_fd1.most_common(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
